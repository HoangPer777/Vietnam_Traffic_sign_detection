{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12282800,"sourceType":"datasetVersion","datasetId":7740790},{"sourceId":12321360,"sourceType":"datasetVersion","datasetId":7766590}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**SET UP VÀ CÀI ĐẶT THƯ VIỆN**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as T\nimport torchvision.transforms.functional as F # Vẫn giữ F vì có thể dùng F.to_tensor\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torch.utils.data import DataLoader\nimport os\nimport json\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nfrom tqdm import tqdm\nfrom torch.amp import autocast, GradScaler\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2025-06-29T15:28:16.684484Z","iopub.execute_input":"2025-06-29T15:28:16.684774Z","iopub.status.idle":"2025-06-29T15:28:23.250877Z","shell.execute_reply.started":"2025-06-29T15:28:16.684751Z","shell.execute_reply":"2025-06-29T15:28:23.250261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**ĐƯỜNG DẪN**","metadata":{}},{"cell_type":"code","source":"COCO_DATASET_BASE_PATH = '/kaggle/input/vietnam-traffic-sign-coco/faster_rcnn_coco_dataset' \nLOAD_EPOCH = 5 # \nmodel_path_to_load = f'/kaggle/input/mycheckpoint/faster_rcnn_model_epoch_{LOAD_EPOCH}.pth'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T15:28:23.252015Z","iopub.execute_input":"2025-06-29T15:28:23.252388Z","iopub.status.idle":"2025-06-29T15:28:23.255961Z","shell.execute_reply.started":"2025-06-29T15:28:23.252364Z","shell.execute_reply":"2025-06-29T15:28:23.255279Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**HYPERPARAMETER VÀ TRAIN MODEL**","metadata":{}},{"cell_type":"code","source":"# --- Cấu hình chung ---\nNUM_CLASSES = 29 + 1 \nEPOCHS = 15 # \nBATCH_SIZE = 4 \nLEARNING_RATE = 0.001\nMOMENTUM = 0.97\nWEIGHT_DECAY = 0.0005\nWARMUP_EPOCHS = 3 # Số epoch dùng cho warm-up\nWARMUP_FACTOR = 1/3 # Tốc độ học khởi đầu = LEARNING_RATE * WARMUP_FACTOR\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Sử dụng thiết bị: {device}\")\n\nTRAIN_ANNOTATIONS_FILE = os.path.join(COCO_DATASET_BASE_PATH, 'annotations', 'instances_train.json')\nVAL_ANNOTATIONS_FILE = os.path.join(COCO_DATASET_BASE_PATH, 'annotations', 'instances_val.json')\nIMAGES_DIR = os.path.join(COCO_DATASET_BASE_PATH, 'images')\n\n# --- Lớp Dataset Tùy chỉnh cho COCO ---\nclass CustomCOCODataset(torchvision.datasets.CocoDetection):\n    def __init__(self, root, annFile, is_train=True):\n        super().__init__(root, annFile)\n        self.is_train = is_train\n\n        # Định nghĩa các phép biến đổi torchvision.transforms\n        # Gợi ý tối ưu: Thêm các phép tăng cường dữ liệu ở đây cho chế độ huấn luyện\n        if self.is_train:\n            self.transform = T.Compose([\n                T.ToTensor(),\n            ])\n        else:\n            self.transform = T.Compose([\n                T.ToTensor(),\n            ])\n\n    def __getitem__(self, idx):\n        img_id = self.ids[idx]\n        img_pil, target_list_of_dicts = super().__getitem__(idx)\n\n        # Áp dụng torchvision.transforms cho ảnh\n        img_tensor = self.transform(img_pil)\n\n        valid_boxes = []\n        valid_labels = []\n        for ann in target_list_of_dicts:\n            bbox = ann['bbox']\n            x_min, y_min, w, h = bbox\n            x_max = x_min + w\n            y_max = y_min + h\n\n            if w > 0 and h > 0 and ann['area'] > 0:\n                valid_boxes.append([x_min, y_min, x_max, y_max]) # Pascal VOC format\n                valid_labels.append(ann['category_id'])\n\n        boxes_transformed = torch.tensor(valid_boxes, dtype=torch.float32)\n        labels_transformed = torch.tensor(valid_labels, dtype=torch.int64)\n\n        if boxes_transformed.numel() == 0:\n            boxes_transformed = torch.zeros((0, 4), dtype=torch.float32)\n            labels_transformed = torch.zeros((0,), dtype=torch.int64)\n\n        image_id = torch.tensor([img_id])\n        area = (boxes_transformed[:, 3] - boxes_transformed[:, 1]) * \\\n               (boxes_transformed[:, 2] - boxes_transformed[:, 0])\n        iscrowd = torch.zeros((len(boxes_transformed),), dtype=torch.int64)\n\n        target_frcnn = {}\n        target_frcnn[\"boxes\"] = boxes_transformed\n        target_frcnn[\"labels\"] = labels_transformed\n        target_frcnn[\"image_id\"] = image_id\n        target_frcnn[\"area\"] = area\n        target_frcnn[\"iscrowd\"] = iscrowd\n\n        return img_tensor, target_frcnn\n\n# Hàm collate_fn vẫn giữ nguyên\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\n# Khởi tạo Dataset và DataLoader\ntrain_dataset = CustomCOCODataset(root=IMAGES_DIR,\n                                  annFile=TRAIN_ANNOTATIONS_FILE,\n                                  is_train=True)\n\nval_dataset = CustomCOCODataset(root=IMAGES_DIR,\n                                annFile=VAL_ANNOTATIONS_FILE,\n                                is_train=False)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n\n# --- Hàm hỗ trợ tính toán mAP bằng pycocotools ---\ndef evaluate_coco(model, data_loader, coco_gt, device):\n    model.eval()\n    results = []\n\n    for images, targets in tqdm(data_loader, desc=\"Collecting Predictions\"):\n        images = list(img.to(device) for img in images)\n\n        batch_image_ids = [t[\"image_id\"].item() for t in targets]\n\n        with autocast(device_type='cuda'):\n            outputs = model(images)\n\n        for i, output in enumerate(outputs):\n            image_id = batch_image_ids[i]\n\n            boxes = output[\"boxes\"].detach().cpu().numpy()\n            labels = output[\"labels\"].detach().cpu().numpy()\n            scores = output[\"scores\"].detach().cpu().numpy()\n\n            for box, label, score in zip(boxes, labels, scores):\n                x_min, y_min, x_max, y_max = box\n                width = x_max - x_min\n                height = y_max - y_min\n\n                results.append({\n                    \"image_id\": int(image_id),\n                    \"category_id\": int(label),\n                    \"bbox\": [float(x_min), float(y_min), float(width), float(height)],\n                    \"score\": float(score)\n                })\n\n    temp_results_file = \"temp_results.json\"\n    with open(temp_results_file, \"w\") as f:\n        json.dump(results, f)\n\n    if not results:\n        print(\"Không có dự đoán nào được tạo ra. Không thể tính toán mAP.\")\n        return 0.0, 0.0\n\n    coco_dt = coco_gt.loadRes(temp_results_file)\n\n    coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n\n    coco_eval.params.imgIds = coco_gt.getImgIds()\n\n    coco_eval.evaluate()\n    coco_eval.accumulate()\n    coco_eval.summarize()\n\n    mAP = coco_eval.stats[0]\n    mAP_50 = coco_eval.stats[1]\n\n    os.remove(temp_results_file)\n\n    return mAP, mAP_50\n\n# --- Tải Mô hình Faster R-CNN ---\nweights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\nmodel = fasterrcnn_resnet50_fpn(weights=weights)\n\nin_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n\n# --- Định nghĩa Optimizer và Learning Rate Scheduler ---\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n\nwarmup_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=WARMUP_FACTOR, total_iters=WARMUP_EPOCHS)\nmain_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n\nlr_scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup_scheduler, main_scheduler], milestones=[WARMUP_EPOCHS])\n\nscaler = GradScaler()\n\n# --- Tải mô hình đã lưu để tiếp tục huấn luyện ---\n\nif os.path.exists(model_path_to_load) and LOAD_EPOCH > 0:\n    model.load_state_dict(torch.load(model_path_to_load, map_location=device))\n    print(f\"Đã tải mô hình từ: {model_path_to_load} để tiếp tục huấn luyện.\")\n    for _ in range(LOAD_EPOCH):\n        lr_scheduler.step()\nelse:\n    print(f\"Không tìm thấy file mô hình tại {model_path_to_load} hoặc LOAD_EPOCH là 0. Bắt đầu huấn luyện từ đầu.\")\n\nmodel.to(device)\nmodel.train()\n\n# --- Danh sách để lưu trữ các chỉ số qua các epoch ---\ntrain_losses = []\nval_mAP_50_95 = []\nval_mAP_50 = []\nepochs_ran = []\nprint(\"\\n--- Bắt đầu huấn luyện Faster R-CNN ---\")\ncoco_val_gt = COCO(VAL_ANNOTATIONS_FILE)\n\nfor epoch in range(LOAD_EPOCH, EPOCHS):\n    current_epoch_display = epoch + 1\n    epochs_ran.append(current_epoch_display)\n\n    model.train()\n    total_loss = 0\n\n    print(f\"\\nEpoch {current_epoch_display}/{EPOCHS}\")\n    for i, (images, targets) in enumerate(tqdm(train_loader, desc=\"Training\")):\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        optimizer.zero_grad()\n\n        with autocast(device_type='cuda'):\n            loss_dict = model(images, targets)\n            losses = sum(loss for loss in loss_dict.values())\n\n        scaler.scale(losses).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += losses.item()\n\n    lr_scheduler.step()\n\n    avg_train_loss = total_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n    print(f\"Loss Epoch {current_epoch_display}: {avg_train_loss:.4f}\")\n\n    # --- Đánh giá trên tập Validation (có tính mAP) ---\n    print(\"\\n--- Bắt đầu đánh giá trên tập Validation ---\")\n    model.eval()\n    with torch.no_grad():\n        # Không cần vòng lặp ở đây, evaluate_coco sẽ tự gọi model(images)\n        pass \n\n    print(f\"\\n--- Tính toán mAP cho Epoch {current_epoch_display} ---\")\n    mAP_val, mAP_50_val = evaluate_coco(model, val_loader, coco_val_gt, device)\n    val_mAP_50_95.append(mAP_val)\n    val_mAP_50.append(mAP_50_val)\n    print(f\"mAP (IoU=0.50:0.95): {mAP_val:.4f}\")\n    print(f\"mAP@0.50: {mAP_50_val:.4f}\")\n\n    # --- Lưu mô hình sau mỗi epoch ---\n    model_save_path = f\"faster_rcnn_model_epoch_{current_epoch_display}.pth\"\n    torch.save(model.state_dict(), model_save_path)\n    print(f\"Đã lưu mô hình tại: {model_save_path}\")\n\nprint(\"\\n--- Huấn luyện Faster R-CNN hoàn tất ---\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-06-29T15:28:23.256524Z","iopub.execute_input":"2025-06-29T15:28:23.256758Z","iopub.status.idle":"2025-06-29T19:17:27.145668Z","shell.execute_reply.started":"2025-06-29T15:28:23.256735Z","shell.execute_reply":"2025-06-29T19:17:27.145025Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**VISUALIZATION**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\n\n# Biểu đồ Loss\nplt.subplot(1, 2, 1)\nplt.plot(epochs_ran, train_losses, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss per Epoch')\nplt.legend()\nplt.grid(True)\n\n# Biểu đồ mAP\nplt.subplot(1, 2, 2)\nplt.plot(epochs_ran, val_mAP_50_95, label='mAP (IoU=0.50:0.95)')\nplt.plot(epochs_ran, val_mAP_50, label='mAP@0.50')\nplt.xlabel('Epoch')\nplt.ylabel('mAP')\nplt.title('Validation mAP per Epoch')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:17:27.146851Z","iopub.execute_input":"2025-06-29T19:17:27.147106Z","iopub.status.idle":"2025-06-29T19:17:27.523708Z","shell.execute_reply.started":"2025-06-29T19:17:27.147087Z","shell.execute_reply":"2025-06-29T19:17:27.522996Z"}},"outputs":[],"execution_count":null}]}